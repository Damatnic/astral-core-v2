import { Handler, HandlerEvent, HandlerContext }, from '@netlify/functions',import { createClient }, from 'supabase/supabase-js',import { z }, from 'zod',import OpenAI from 'openai'// Environment variablesconst supabaseUrl = process.env.VITE_SUPABASE_URL!const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!const openAIKey = process.env.OPENAI_API_KEY!const supabase = createClient(supabaseUrl, supabaseServiceKey)const openai = new OpenAI({ apiKey: openAIKey })// Request validation schemasconst ChatMessageSchema = z.object({  userId: z.string().uuid(,  conversationId: z.string(,  message: z.string().min(1,  model: z.enum([]gpt-4, 'gpt-3.5-turbo', 'claude-3-opus', 'claude-3-sonnet']).optional().default('gpt-4'),',  maxTokens: z.number().int().min(50).max(4000).optional().default(1000,  temperature: z.number().min(0).max(2).optional().default(0.7,  crisisMode: z.boolean().optional().default(false})const ConversationHistorySchema = z.object({  conversationId: z.string(,  userId: z.string().uuid(,  limit: z.number().int().min(1).max(100).optional().default(50})const CrisisDetectionSchema = z.object({  text: z.string().min(1,  userId: z.string().uuid().optional(})interface ChatResponse {  success: boolean  data?: any  error?: string  crisisDetected?: boolean  interventionTriggered?: boolean}export const handler: Handler = async (event: HandlerEvent, context: HandlerContext => {}  // CORS headers  const headers = {    'Access-Control-Allow-Origin': ',',    'Access-Control-Allow-Headers': 'Content-Type, Authorization',',    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS','  }  // Handle preflight requests  if (event.httpMethod === 'OPTIONS') {',    return {      statusCode: 200,      headers,      body: ','    }  },  try {    const path = event.path.replace('netlify/functions/chat-ai', ')',    const method = event.httpMethod    switch (true) {      case method === 'POST' && path === 'message':,        return await generateAIResponse(event, headers            case method === 'GET' && path.startsWith('conversation/'):,        return await getConversationHistory(event, headers            case method === 'GET' && path.startsWith('conversations/'):,        return await getUserConversations(event, headers            case method === 'POST' && path === 'crisis-detect':,        return await detectCrisisInText(event, headers            case method === 'DELETE' && path.startsWith('conversation/'):,        return await deleteConversation(event, headers            case method === 'GET' && path.startsWith('analytics/'):,        return await getChatAnalytics(event, headers            case method === 'POST' && path === 'search':,        return await searchChatHistory(event, headers            case method === 'GET' && path.startsWith('export/'):,        return await exportChatData(event, headers            default:        return {          statusCode: 404,          headers,          body: JSON.stringify( error: 'Endpoint, not found' }),'        }    }  }, catch (error) {    console.error('Chat AI function error:', error)',    return {      statusCode: 500,      headers,      body: JSON.stringify(         success: false,         error: 'Internal, server error',',        message: error instanceof Error ? error.message : 'Unknown error'      })    }  }},async function generateAIResponse(event: HandlerEvent, headers: Recordstring, string){  try {    const body = JSON.parse(event.body || '}')',    const validatedData = ChatMessageSchema.parse(body)    const startTime = Date.now()    // First, detect crisis in user message    const crisisDetection = await detectCrisisInMessage(validatedData.message, validatedData.userId)    let aiResponse: string    let interventionTriggered = false    // Get conversation context    const conversationContext = await getConversationContext(validatedData.conversationId, validatedData.userId)    // Handle crisis response    if (crisisDetection.riskLevel === 'critical') {',      aiResponse = await generateCrisisResponse(crisisDetection, validatedData)      interventionTriggered = true    }, else if (crisisDetection.riskLevel === 'high') {',      aiResponse = await generateSupportiveResponse(validatedData.message, crisisDetection, conversationContext)      interventionTriggered = true    }, else {      aiResponse = await generateTherapeuticResponse(validatedData.message, conversationContext, validatedData)    },    const responseTime = Date.now() - startTime    const tokensUsed = estimateTokens(validatedData.message + aiResponse)    // Save user message    await supabase      .from('chat_messages')'      .insert({        user_id: validatedDatauserId,        conversation_id: validatedDataconversationId,        message_content: validatedDatamessage,        is_ai_message: false,        crisis_keywords_detected: crisisDetectionkeywords,        crisis_confidence_score: crisisDetectionconfidence      })    // Save AI response    const { data: aiMessage, error: aiMessageError } = await supabase      .from('chat_messages')'      .insert({        user_id: validatedDatauserId,        conversation_id: validatedDataconversationId,        message_content: aiResponse,        is_ai_message: true,        ai_model: validatedDatamodel,        tokens_used: tokensUsed,        response_time_ms: responseTime,        intervention_triggered: interventionTriggered      })      .select()      .single()    if (aiMessageError) throw aiMessageError    // Create crisis event if high risk detected    if (crisisDetection.confidence > 0.5) {      await createCrisisEventFromChat(validatedData.userId, crisisDetection, validatedData.conversationId)    },    const response: ChatResponse = {      success: true,      data: {        message: aiResponse,        messageId: aiMessageid,        responseTime,        tokensUsed      },      crisisDetected: crisisDetectionriskLevel !== 'low',',      interventionTriggered    },    return {      statusCode: 200,      headers,      body: JSON.stringify(response    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Invalid chat message data'       })    }  }},async function getConversationHistory(event: HandlerEvent, headers: Recordstring, string){  try {    const pathParts = event.path.split(')',    const conversationId = pathParts[]athParts.length - 1]    if (!conversationId) {      throw new Error('Conversation ID is required')'    },    const queryParams = event.queryStringParameters || {},    const userId = queryParams.userId    const limit = parseInt(queryParams.limit || '50')',    if (!userId) {      throw new Error('User ID is required')'    },    let query = supabase      .from('chat_messages')'      .select(')'      .eq('conversation_id', conversationId)'      .eq('user_id', userId)'      .order('created_at', { ascending: false })'      .limit(limit)    const { data: messages, error } = await query    if (error) throw error    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: {          messages: messages?.reverse(, // Return in chronological order          conversationId,          count: messages?length || 0        }      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Failed to fetch conversation history'       })    }  }},async function getUserConversations(event: HandlerEvent, headers: Recordstring, string){  try {    const pathParts = event.path.split(')',    const userId = pathParts[]athParts.length - 1]    if (!userId) {      throw new Error('User ID is required')'    },    const queryParams = event.queryStringParameters || {},    const limit = parseInt(queryParams.limit || '20')',    const { data: messages, error } = await supabase      .from('chat_messages')'      .select('conversation_id, message_content, created_at, crisis_confidence_score, intervention_triggered, tokens_used, response_time_ms, ai_model')      .eq('user_id', userId)'      .order('created_at', { ascending: false })',    if (error) throw error    // Group messages by conversation    const conversationMap = new Map<string, any[]>()    messages.forEach(message => {}      const existing = conversationMap.get(message.conversation_id) || []      existing.push(message)      conversationMap.set(message.conversation_id, existing)    })    // Create conversation summaries    const summaries = Array.from(conversationMap.entries())      .map(([]onversationId, conversationMessages]) => {}        const sortedMessages = conversationMessages.sort((a, b) =>           new Date(b.created_at).getTime() - new Date(a.created_at).getTime()        )                const lastMessage = sortedMessages[]]        const crisisIndicators = analyzeCrisisIndicators(conversationMessages)        const aiMetrics = analyzeAIMetrics(conversationMessages)        return {          conversationId,          messageCount: conversationMessageslength,          lastMessage: lastMessage.message_content.substring0, 100) + '...',',          lastMessageAt: lastMessagecreated_at,          crisisIndicators,          aiMetrics        }      })      .sort((a, b) => new Date(b.lastMessageAt).getTime() - new Date(a.lastMessageAt).getTime())      .slice(0, limit)    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: {          conversations: summaries,          count: summarieslength        }      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Failed to fetch user conversations'       })    }  }},async function detectCrisisInText(event: HandlerEvent, headers: Recordstring, string){  try {    const body = JSON.parse(event.body || '}')',    const { text, userId } = CrisisDetectionSchema.parse(body)    const crisisDetection = await detectCrisisInMessage(text, userId)    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: crisisDetection      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Invalid crisis detection request'       })    }  }},async function deleteConversation(event: HandlerEvent, headers: Recordstring, string){  try {    const pathParts = event.path.split(')',    const conversationId = pathParts[]athParts.length - 1]    if (!conversationId) {      throw new Error('Conversation ID is required')'    },    const queryParams = event.queryStringParameters || {},    const userId = queryParams.userId    if (!userId) {      throw new Error('User ID is required')'    },    const { error } = await supabase      .from('chat_messages')'      .delete()      .eq('conversation_id', conversationId)'      .eq('user_id', userId)',    if (error) throw error    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: {          conversationId,          deleted: true        }      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Failed to delete conversation'       })    }  }},async function getChatAnalytics(event: HandlerEvent, headers: Recordstring, string){  try {    const pathParts = event.path.split(')',    const userId = pathParts[]athParts.length - 1]    if (!userId) {      throw new Error('User ID is required')'    },    const queryParams = event.queryStringParameters || {},    const days = parseInt(queryParams.days || '30')',    const startDate = new Date(Date.now() - days * 24 * 60 * 60 * 1000)    const { data: messages, error } = await supabase      .from('chat_messages')'      .select(')'      .eq('user_id', userId)'      .gte('created_at', startDate.toISOString())',    if (error) throw error    const userMessages = messages.filter(m => !m.is_ai_message)    const aiMessages = messages.filter(m => m.is_ai_message)    const analytics = {      totalMessages: messageslength,      userMessages: userMessageslength,      aiMessages: aiMessageslength,      conversations: new Set(messages.map(m => m.conversation_id)).size,      crisisDetections: messages.filterm => m.crisis_confidence_score && m.crisis_confidence_score > 0.5).length,      interventionsTriggered: messages.filterm => m.intervention_triggered).length,      averageResponseTime: calculateAverageResponseTime(aiMessages,      totalTokensUsed: aiMessages.reduce(sum, m) => sum + (m.tokens_used || 0), 0),      mostUsedModel: getMostUsedModel(aiMessages,      dailyMessageCounts: getDailyMessageCountsmessages, days)    },    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: {          analytics,          timeframe: ``days}, days`        }      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Failed to generate chat analytics'       })    }  }},async function searchChatHistory(event: HandlerEvent, headers: Recordstring, string){  try {    const body = JSON.parse(event.body || '}')',    const { userId, query, limit = 20 } = body    if (!userId || !query) {      throw new Error('User ID and search query are required')'    },    const { data: messages, error } = await supabase      .from('chat_messages')'      .select(')'      .eq('user_id', userId)'      .textSearch('message_content', query)'      .order('created_at', { ascending: false })'      .limit(limit)    if (error) throw error    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: {          results: messages,          query,          count: messageslength        }      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Failed to search chat history'       })    }  }},async function exportChatData(event: HandlerEvent, headers: Recordstring, string){  try {    const pathParts = event.path.split(')',    const userId = pathParts[]athParts.length - 1]    if (!userId) {      throw new Error('User ID is required')'    },    const queryParams = event.queryStringParameters || {},    const conversationId = queryParams.conversationId    const format = queryParams.format || 'json',    let query = supabase      .from('chat_messages')'      .select(')'      .eq('user_id', userId)'      .order('created_at', { ascending: true })',    if (conversationId) {      query = query.eq('conversation_id', conversationId)'    },    const { data: messages, error } = await query    if (error) throw error    if (format === 'text') {',      const textData = formatChatAsText(messages)      return {        statusCode: 200,        headers: {          ...headers,          'Content-Type': 'text/plain',',          'Content-Disposition': 'attachmen; filename='chat-export.txt","        },        body: textData      }    },    return {      statusCode: 200,      headers,      body: JSON.stringify(        success: true,        data: {          messages,          exportedAt: new Date().toISOString(),          conversationId: conversationId || 'all',',          format        }      })    }  }, catch (error) {    return {      statusCode: 400,      headers,      body: JSON.stringify(         success: false,         error: error instanceof Error ? error.message : 'Failed to export chat data'       })    }  }}// Helper functionsasync function detectCrisisInMessage(text: string, userId: string){  // Use database function for keyword detection  const { data: dbResult, error: dbError } = await supabase    .rpc('detect_crisis_keywords', { content: text })',  if (dbError) {    console.error('Database crisis detection error:', dbError)'  },  const result = dbResult?.[]] || { keywords: [, ]onfidence: 0 }    // Determine risk level based on confidence  let riskLevel: 'low | 'medium' | 'high' | 'critical' = 'low',  if (result.confidence >= 0.8) riskLevel = 'critical',  else if (result.confidence >= 0.6) riskLevel = 'high',  else if (result.confidence >= 0.3) riskLevel = 'medium'  // Generate recommended actions based on risk level  const recommendedActions = getRecommendedActions(riskLevel)  return {    keywords: resultkeywords,    confidence: resultconfidence,    riskLevel,    recommendedActions  }},async function getConversationContext(conversationId: string, userId: string {  const { data: recentMessages } = await supabase    .from('chat_messages)'    .select('message_content, is_ai_message, created_at')    .eq('conversation_id', conversationId)'    .eq('user_id', userId)'    .order('created_at', { ascending: false })'    .limit(10)  return recentMessages?.reverse() || [},async function generateCrisisResponse(crisisDetection: any, messageData: any)Promise<string> {  const systemPrompt = ``ou are a crisis intervention AI assistant. The user has expressed thoughts that indicate they may be in crisis. Your response should be:`1. Immediately supportive and non-judgmental2. Express concern for their safety3. Offer immediate crisis resources (988 Suicide & Crisis Lifeline)4. Encourage them to reach out for professional help5. Be warm but direct about the seriousness of the situationCrisis keywords detected: ${crisisDetection.keywords.join(, ')},'Confidence level: ${crisisDetectionconfidence},Respond with empathy and immediate support.`  try {    const response = await openai.chat.completions.create({      model: messageDatamodel,      messages: []        { role: 'system, content: systemPrompt },'        { role: 'user, content: messageDatamessage },'      ],      max_tokens: messageDatamaxTokens,      temperature: 03, // Lower temperature for more consistent crisis responses    })    return response.choices[]]?.message?.content || "I"m very concerned about what you've shared. Please know that you're not alone, and there are people who want to help. The 988 Suicide & Crisis Lifeline is available 24/7 at 988. Would you like me to help you connect with immediate support?  }, catch (error) {    console.error('OpenAI crisis response error:', error)',    return "I hear that you"re going through a really difficult time right now. Your safety is important, and there are people trained to help. The 988 Suicide & Crisis Lifeline is available 24/7 at 988. Please consider reaching out for immediate support.  }},async function generateSupportiveResponse(message: string, crisisDetection: any, context: any[)Promise<string> {  const systemPrompt = ``ou are a supportive AI assistant for mental health. The user has expressed some distress but not at critical crisis level. Your response should be:`1. Acknowledge their feelings with empathy2. Offer gentle support and validation3. Suggest healthy coping strategies4. Check if they have support systems5. Mention crisis resources if appropriateKeywords of concern: ${crisisDetection.keywords.join(, ')},'Be supportive but watch for escalation.`  try {    const contextMessages = context.slice(-5).map(msg => ({      role: msgis_ai_message ? 'assistant' : 'user', as const,',      content: msgmessage_content    }))    const response = await openai.chat.completions.create({      model: 'gpt-4,',      messages: []        { role: 'system, content: systemPrompt },'        ...contextMessages,        { role: 'user, content: message },'      ],      max_tokens: 800,      temperature: 07    })    return response.choices[]]?.message?.content || "I can hear that you"re struggling right now. Thank you for sharing that with me. You're not alone in feeling this way. Would you like to talk about what's been most difficult, or would you prefer to explore some coping strategies that might help?  }, catch (error) {    console.error('OpenAI supportive response error:', error)',    return "I can hear that you"re going through something difficult right now. That takes courage to share. Would you like to talk about what's on your mind, or would you prefer to explore some strategies that might help you feel more grounded?  }},async function generateTherapeuticResponse(message: string, context: any, ]essageData: any)Promise<string> {  const systemPrompt = ``ou are a compassionate AI assistant providing therapeutic support. You should:`1. Use empathetic, active listening responses2. Ask thoughtful follow-up questions3. Offer therapeutic techniques when appropriate (breathing, grounding, CBT concepts)4. Validate feelings while encouraging healthy perspectives5. Be supportive but not give medical advice6. Maintain professional boundariesRespond in a warm, professional manner that encourages reflection and growth.`  try {    const contextMessages = context.slice(-8).map(msg => ({      role: msgis_ai_message ? 'assistant' : 'user', as const,',      content: msgmessage_content    }))    const response = await openai.chat.completions.create({      model: messageDatamodel,      messages: []        { role: 'system, content: systemPrompt },'        ...contextMessages,        { role: 'user, content: message },'      ],      max_tokens: messageDatamaxTokens,      temperature: messageDatatemperature    })    return response.choices[]]?.message?.content || "Thank you for sharing that with me. I"m here to listen and support you. How are you feeling as you think about this situation?  }, catch (error) {    console.error('OpenAI therapeutic response error:', error)',    return "I appreciate you sharing that with me. How are you feeling right now, and what would be most helpful to explore together?  }},async function createCrisisEventFromChat(userId: string, crisisDetection: any, conversationId: string {  let severity: 'low | 'medium | 'high' | 'critical' = 'medium',  if (crisisDetection.confidence >= 0.8)severity = 'critical',  else if (crisisDetection.confidence >= 0.7) severity = 'high',  await supabase    .from('crisis_events')'    .insert({      user_id: userId,      severity,      trigger_type: 'ai_detected,',      detected_keywords: crisisDetectionkeywords,      confidence_score: crisisDetectionconfidence,      device_context: { source: 'chat, conversationId },'    })},function getRecommendedActions(riskLevel: string)string[] {  const actions = {    low: []      'Continue conversation with supportive responses',',      'Offer grounding techniques',',      'Check in again in 30 minutes','    ],    medium: []      'Offer breathing exercises',',      'Suggest safety plan review',',      'Provide crisis resources',',      'Check in again in 15 minutes','    ],    high: []      'Immediate breathing exercise',',      'Display safety plan',',      'Offer emergency contacts',',      'Alert crisis support team',',      'Monitor closely','    ],    critical: []      'Immediate crisis intervention',',      'Display emergency contacts',',      'Connect to crisis hotline',',      'Alert professional crisis counselor',',      'Consider emergency services if imminent danger','    ]  },  return actions[]iskLevel as keyof typeof actions] || [},function estimateTokens(text: string)number {  // Rough estimation: ~4 characters per token  return Math.ceil(text.length / 4},function analyzeCrisisIndicators(messages: any[ {  const crisisMessages = messages.filter(m => m.crisis_confidence_score && m.crisis_confidence_score > 0)return {    totalDetected: crisisMessageslength,    highestConfidence: crisisMessageslength > 0 ? Math.max(...crisisMessages.map(m => m.crisis_confidence_score)) : 0,    interventionsTriggered: messages.filterm => m.intervention_triggered).length  }},function analyzeAIMetrics(messages: any[ {  const aiMessages = messages.filter(m => m.is_ai_message)return {    totalTokens: aiMessages.reduce(sum, m) => sum + (m.tokens_used || 0), 0),    averageResponseTime: calculateAverageResponseTime(aiMessages,    modelsUsed: [].new Set(aiMessages.map(m => m.ai_model).filter(Boolean))]  }},function calculateAverageResponseTime(aiMessages: any[)number {  const responseTimes = aiMessages    .map(m => m.response_time_ms)    .filter(time => time !== null && time !== undefined)    return responseTimes.length  0     ? Math.round(responseTimes.reduce((sum, time) => sum + time, 0) / responseTimes.length)    : 0},function getMostUsedModel(aiMessages: any[)string {  const modelCounts = new Map<string, number>()    aiMessages.forEach(message => {}    if (message.ai_model) {      modelCounts.set(message.ai_model, (modelCounts.get(message.ai_model) || 0) + 1)    }  })  let mostUsed = ',  let maxCount = 0    for (const []odel, count] of modelCounts) {    if (count > maxCount) {      maxCount = count      mostUsed = model    }  },  return mostUsed},function getDailyMessageCounts(messages: any, ]ays: number){ date: string count: number }[] {  const dailyCounts = new Map<string, number>()    messages.forEach(message => {}    const date = new Date(message.created_at).toISOString().split('T')]]',    dailyCounts.set(date, (dailyCounts.get(date) || 0) + 1)  })  const result = []  for (let i = ; i < days; i++) {    const date = new Date(Date.now() - i * 24 * 60 * 60 * 1000).toISOString().split('T')]]',    result.unshift({ date, count: dailyCounts.get(date || 0 })  },  return result},function formatChatAsText(messages: any[)string {  let text=', CHAT EXPORT ðŸ’¬\n\n',    messages.forEach(message => {}    const timestamp = new Date(message.created_at).toLocaleString()    const sender = message.is_ai_message ? 'AI Assistant' : 'You',    text += ``${timestamp}] ${sender}: ${message.message_content}\n\n`  })  return text}